{
\chapter{Explicit and implicit regularisation}
\label{ch:reg}
\renewcommand{\chapterpath}{includes/regularisation}
%
\begin{outreach}
    \item \textit{Data augmentation instead of explicit regularization.} Alex Hern{\'a}ndez-Garc{\'i}a, Peter K{\"o}nig. arXiv preprint arXiv:1806.03852, 2018.
\end{outreach}
%
One of the central issues in machine learning research and application is finding ways of improving generalisation. Regularisation, broadly defined as any modification applied to a learning algorithm that helps the model generalise better, plays therefore a key role in machine learning\footnote{In Chapter~\ref{ch:background} we review the fundamentals of machine learning and in particular, Section~\ref{sec:background-regularisation} reviews the essential aspects of regularisation to understand this and the upcoming chapters.}. In the case of deep learning, where neural networks tend to have several orders of magnitude more parameters than training examples, statistical learning theory (Section~\ref{sec:background-generalisation}) indicates that regularisation becomes even more crucial. Accordingly, a myriad of techniques have been proposed as regularisers (Section~\ref{sec:background-regularisation}): weight decay \citep{hanson1989wd} and other $L^p$ penalties on the learnable parameters; dropout---random dropping of units during training---\citep{srivastava2014dropout} and stochastic depth---random dropping of whole layers---\citep{huang2016stochasticdepth}, to name a few. 

Moreover, whereas in simpler machine learning algorithms the regularisers can be easily identified as explicit terms in the objective function, in modern deep neural networks the sources of regularisation are not only explicit but implicit \citep{neyshabur2014implicitreg}.  In this regard, many techniques have been studied for their regularisation effect, despite not being explicitly intended as such. Examples are convolutional layers \citep{lecun1990conv}, batch normalisation \citep{ioffe2015batchnorm} and data augmentation. In sum, there are multiple elements in deep learning that contribute to reducing overfitting and thus improve generalisation.

It is common practice in both the scientific literature and application to incorporate several of these regularisation techniques in the training procedure of neural networks. For instance, weight decay, dropout and data augmentation have been used jointly in multiple well-known architectures \citep{tan2019efficientnet, huang2017densenet, zagoruyko2016wrn, springenberg2014allcnn}. It is therefore implicitly assumed that each technique  is necessary and contributes additively to improving generalisation. However, the interplay between regularisation techniques is yet to be well understood and might be an important piece for the puzzle of why and when deep networks generalise. 

In Chapter~\ref{ch:daugreg}, we will focus on contrasting some specific forms of regularisation, namely weight decay, dropout and data augmentation. This chapter serves as a preamble of the following one. Here, we will provide definitions of two terms that have been widely but ambiguously used in the machine learning literature: explicit and implicit regularisation. We contend that these terms are useful to understand and explain the role of regularisation in artificial neural networks, as reflected by their use in the literature. Therefore, it is important to settle the precise meaning of the terms and provide examples. Besides being helpful to interpret the results in Chapter~\ref{ch:daugreg}, we also hope that this is a useful contribution to the machine learning community.

\section{Why do we need definitions?}
\label{sec:reg-why}
While several regularisation taxonomies have been proposed (see Section~\ref{sec:reg-taxonomies}), to the best of our knowledge there is no formal definitions of explicit and implicit regularisation in the machine literature. Nonetheless, the terms have been widely used \cite{neyshabur2014implicitreg, zhang2016understandingdl, wilson2017neurips, mesnil2011transferlearning, poggio2017theory3, martin2018selfregularisation, achille2018emergence}. This could suggest that the concepts are ingrained in the field and well understood by the community. However, by analysing the use of the terms explicit and implicit regularisation in the literature and in discussions with practitioners one can see that there is a high degree of ambiguity. In this section we will review some examples and motivate the need for formal definitions.

The PhD thesis by \citet{neyshabur2017thesis} is devoted to the study of implicit regularisation in deep learning. For instance, Neyshabur shows that common optimisation methods for deep learning, such as stochastic gradient descent (SGD), introduce an inductive bias that lead to better generalisation. That is, SGD \textit{implicitly} regularises the learning process. However, the notion and definition of implicit regularisation is only implied in Neyshabur's PhD thesis and related works. 

Some may argue that the definitions are not necessary. By looking at one single piece of work, even without a formal definition, the meaning may be inferred from the use. However, when one considers a larger body of work by multiple authors, differences and even contradictions emerge. In the work by Neyshabur and colleagues \citep{neyshabur2017thesis, neyshabur2014implicitreg}, it can be interpreted that implicit regularisation refers to the generalisation improvement provided by techniques such as stochastic gradient descent (SGD) that are not \textit{typically} considered as regularisation. By extension, explicit regularisation would refer to those other techniques: ``we are not including any explicit regularisation, neither as an explicit penalty term nor by modifying optimisation through, e.g., drop-outs, weight decay, or with one-pass stochastic methods'' \citep{neyshabur2017thesis}. In \citet{poggio2017theory3}, it can be interpreted that implicit regularisation refers to techniques that lead to minimisation of the parameter norm without explicitly optimising for it. By extension, explicit regularisation would refer to classical penalties on the parameter norm, such as weight decay. It is therefore unclear whether other methods such as dropout should be considered explicit or implicit regularisation according to \citet{poggio2017theory3}.

\citet{zhang2016understandingdl} raised the thought-provoking idea that ``explicit regularisation may improve generalisation performance, but is neither necessary nor by itself sufficient for controlling generalisation error.'' The authors came to this conclusion from the observation that turning off the ``explicit regularisers'' of a model does not prevent the model from generalising reasonably well. In their experiments, the explicit regularisation techniques they turned off were, specifically, weight decay, dropout and data augmentation. In this case, it seems that \citet{zhang2016understandingdl} made a distinction based on the mere intention of the practitioner. Under that logic, because data augmentation has to be designed and applied \textit{explicitly}, it would be explicit regularisation. 

These examples illustrate that the terms explicit and implicit regularisation have been used subjectively and inconsistently in the literature. In order to help avoid ambiguity, settle the concepts and facilitate the discussion, in the next section we propose definitions and provide examples to illustrate each category. Further, we will argue that data augmentation is not explicit regularisation and introduce some key differences with respect to explicit regularisation, which will set the grounds for Chapter~\ref{ch:daugreg}. 

\section{Definitions and examples}
\label{sec:reg-definitions}
We propose the following definitions of explicit and implicit regularisation:

\begin{itemize}
\item \textbf{Explicit regularisation techniques} are those techniques which reduce the \textit{representational} capacity of the model class they are applied on. That is, given a model class $\mathcal{H}_0$, for instance a neural network architecture, the introduction of explicit regularisation will span a new hypothesis set $\mathcal{H}_1$,  which is a \textit{proper subset} of the original set, that is $\mathcal{H}_1 \subsetneq \mathcal{H}_0$.
\item \textbf{Implicit regularisation} is the reduction of the generalisation error or overfitting provided by means other than explicit regularisation techniques. Elements that provide implicit regularisation do not reduce the \textit{representational} capacity, but may affect the \textit{effective} capacity of the model: the \textit{achievable} set of hypotheses given the model, the optimisation algorithm, hyperparameters, etc.
\end{itemize}

Note that we define explicit and implicit regularisation by using the concepts of \textit{representational} and \textit{effective} capacity. Although these terms are also used ambiguously by some practitioners, definitions of these concepts can be found in the literature. For instance, the textbook Deep Learning \citep{goodfellow2016dlbook} clearly defines the representational capacity as the ``the family of functions the learning algorithm can choose from'' and explains that the effective capacity ``may be less than the representational capacity'' because the learning algorithm does not always find the ``best function'' due to ``limitations, such as the imperfection of the optimisation algorithm''. Thinking of these \textit{limitations} as implicit regularisation denotes that this can be beneficial. In any case, we here adopt these definitions of representational and effective capacity.

One of the most common explicit regularisation techniques in machine learning is $L^p$-norm regularisation \citep{tikhonov1963regularisation}, of which weight decay is a particular case, widely used in deep learning. Weight decay sets a penalty on the $L^2$ norm of the model's learnable parameters, thus constraining the representational capacity of the model. Dropout \citep{srivastava2014dropout} is another common example of explicit regularisation, where the hypothesis set is reduced by stochastically deactivating a number of neurons during training. Similar to dropout, stochastic depth \citep{huang2016stochasticdepth}, which drops whole layers instead of neurons, is also an explicit regularisation technique.

Regarding implicit regularisation, note first that the above definition does not refer to \textit{techniques}---as in the definition of explicit regularisation---but to a regularisation \textit{effect}, as it can be provided by multiple elements of different nature. For instance, stochastic gradient descent (SGD) is known to have an implicit regularisation effect---reduction of the generalisation error---without constraining the representational capacity \citep{zhang2017sgd}. Batch normalisation neither reduces the capacity, but it improves generalisation by smoothing the optimisation landscape \citep{santurkar2018bn}. Of quite a different nature, but still implicit, is the regularisation effect provided by early stopping \citep{yao2007earlystopping}, which does not reduce the representational but the effective capacity.

In these examples and all other cases of implicit regularisation, we can think of the effect on the capacity in the following way: we start by defining our model class, for instance a neural network, which spans a set of functions $\mathcal{H}_0$ (see Section~\ref{sec:background-elements_ml}). If we decide to train with explicit regularisation, for instance weight decay or dropout, then the model will have access to a smaller set of functions $\mathcal{H}_1 \subsetneq \mathcal{H}_0$, that is the representational capacity. On the contrary, if we decide to train with SGD, batch normalisation or early stopping, the set of functions spanned by the model stays identical. Due to the dynamics and limitations imposed by these techniques, some functions may never be found, but theoretically they could be. In other words, the effective capacity may be smaller but not the representational capacity.

Central to this thesis is data augmentation, a technique that provides an implicit regularisation effect. As we have discussed, \citet{zhang2016understandingdl} considered data augmentation an explicit regularisation technique and was analysed as equivalent in terms of category to weight decay and dropout. However, data augmentation does not reduce the representational capacity of the models and hence, according to our definitions, cannot be considered explicit regularisation. This is relevant to understand the differences between weight decay, dropout and data augmentation that we will present in Chapter~\ref{ch:daugreg}, especially in the context of artificial neural networks.

\section{On the taxonomy of regularisation}
\label{sec:reg-taxonomies}
As in most disciplines, many taxonomies of regularisation techniques for machine learning have been proposed. Being a key ingredient of machine learning theory and practice, machine learning textbooks include a review of regularisation methods. In the case of deep learning, besides the classical regularisation methods used in \textit{traditional} machine learning, multiple new regularisation techniques have been proposed in recent years, and many techniques have been analysed because of their implicit regularisation effect. In this section, we briefly review some taxonomies of regularisation proposed in the literature and discuss their similarity with our definitions. 

In their textbook, \citet{goodfellow2016dlbook} review some of the most common regularisation techniques used to train deep neural networks, but do not discuss the concepts of explicit and implicit regularisation. More recently, \citet{kukavcka2017regularization} provided an extensive review of regularisation methods for deep learning. Although they mention the implicit regularisation effect of techniques such as SGD, no further discussion of the concepts is provided. Nonetheless, they define the category \textit{regularisation via optimisation}, which is somewhat related to implicit regularisation. However, regularisation via optimisation is more specific than our definition; hence, methods such as data augmentation would not fall into that category.

Recently, \citet{guo2018mixup} provided a distinction between \textit{data-independent} and \textit{-dependent} regularisation. They define data-independent regularisation as those techniques that impose certain constraint on the hypothesis set, thus constraining the optimisation problem. Examples are weight decay and dropout. We believe this is closely related to our definition of explicit regularisation. On the other hand, they define data-dependent regularisation as those techniques that make assumptions on the hypothesis set with respect to the training data, as is the case of data augmentation. While we acknowledge the usefulness of such taxonomy, we argue that the division between data-independent and -dependent regularisation leaves some ambiguity about other techniques, such as batch-normalisation, which neither imposes an explicit constraint on the representational capacity nor on the training data. 

On the contrary, our distinction between explicit and implicit regularisation aims at being complete, since implicit regularisation refers to any regularisation effect that does not come from explicit---or data-independent---techniques.

\section{Discussion}
\label{sec:reg-discussion}
The main contribution of this chapter has been the proposal of definitions of explicit and implicit regularisation. These terms that have been widely used in the machine learning literature without being formally defined, hence giving rise to subjective and ambiguous use. With the definition of these important concepts we have set the grounds for our discussion on the rest of this thesis, especially in Chapter~\ref{ch:daugreg}, but we also hope to help settle the concepts and reduce the ambiguity in the literature.

Besides this contribution, it is interesting to draw some connections between the concept of implicit regularisation, the discussion about inductive biases in the Introduction (Chapter~\ref{ch:intro}) and data augmentation. According to our definition above, implicit regularisation is the improvement in generalisation provided by elements that are not explicit regularisation techniques. This is a broad definition that includes many possible sources of implicit regularisation. A concept that underlies many of them is that of inductive bias. The inductive bias encoded in explicit regularisation techniques is simply that smaller models generalise better, which is reminiscent of Occam's razor. While this is a powerful inductive bias, we have discussed that many other sources of inductive bias are possible and are worth exploring.

In this regard, a clear distinction between explicit and implicit regularisation may help in the analysis, especially in the case of deep learning. A striking difference between neural networks and other machine learning algorithms is that deep networks easily scale to an (almost) arbitrarily large number of parameters and still generalise well on a held out test data. Only recently are we starting to understand this phenomenon, which seemed to be at odds with the results of statistical learning theory \citep{belkin2019biasvariance}. 

First, the concept of implicit regularisation may help explain the generalisation of deep neural networks. Second, the fact that very large neural networks can generalise well directly casts doubts on the need for explicit regularisation \citep{zhang2016understandingdl}, that is to constrain the representational capacity. However, most artificial neural networks are still trained with explicit regularisation methods such as weight decay and dropout. In the next chapter, we follow up this idea and directly address the question of whether explicit regularisation is necessary in deep learning, provided enough implicit regularisation is included, specifically data augmentation.

\chapterbibliography
}
