{
\chapter{General discussion}
\label{ch:discussion}
\renewcommand{\chapterpath}{includes/discussion}
In this dissertation I have presented a series of experimental studies and discussions revolving around machine learning for image understanding, visual perception and visual neuroscience. An overarching objective of this work was to explore and exploit the connections between these fields, combining the tools and techniques common to each discipline. 

A central subject of the dissertation has been data augmentation. Data augmentation has been ubiquitously used to train machine learning models on image tasks since the early 1990s, but it has received little scientific attention. In the first part of the thesis, we tried to bring data augmentation to the fore and study its role as implicit regularisation of machine learning algorithms and its potential to incorporate inductive biases from visual perception and biological vision. While on the surface data augmentation is just a method to synthetically increase the number of examples in a data set, we have here analysed it as a technique that encodes effective priors from perception: The image transformations typically included in data augmentation techniques---rotations, translations, scaling, changes in illumination, etc.---coincide with those that are plausible in the real world as we perceive it. Likely not by coincidence, the visual cortex of our brains represents objects under these transformations in a largely robust way.

From a machine learning point of view, data augmentation can be seen as a form of regularisation, in that it helps improve generalisation. Nonetheless, we discussed an important distinction between the type of regularisation provided by data augmentation---implicit regularisation---and explicit regularisation techniques (Chapter~\ref{ch:reg}). The terms explicit and implicit regularisation have appeared frequently in the deep learning literature, but no formal definition had been provided, to the best of our knowledge. Hence, the terms have been in used in an inconsistent and subjective manner. We here provided formal definitions of the two concepts based on their effect on the representational capacity of the model they are applied on, alongside several examples of each category for illustration. Importantly, we argued that data augmentation does not reduce the representational capacity and therefore is not explicit but implicit regularisation. We hope our definitions find consensus in the machine learning community and foster more rigorous discussions about regularisation.

In Chapter~\ref{ch:daugreg}, we delved into the distinction between data augmentation and explicit regularisation. We departed from the hypothesis that data augmentation improves generalisation by increasing the number of training examples through transformations that resemble those that can be find in the real world, while explicit regularisation \textit{simply} relies on the inductive bias that simpler models should generalise better. Although this inductive bias is at the root of the feasibility of learning from data and has proven effective in uncountable applications, the prior knowledge encoded by data augmentation seems intuitively more effective. Accordingly, we challenged the need for explicit regularisation techniques such as weight decay and dropout to train deep neural networks, provided data augmentation is also employed. If large networks with orders of magnitude more learnable parameters than training examples are able to generalise well, is it necessary to constrain their representational capacity? We first derived some theoretical insights from the literature that suggest that weight and dropout can be seen as \textit{naive} data augmentation, that is without domain knowledge. We then confirmed through an empirical evaluation that models trained with data augmentation alone outperform the combination of explicit regularisation and data augmentation typically used in practice.

Although the experimental setup of our empirical study included several network architectures and data sets, with results of over 300 trained models, extended experimentation would be of course desirable. All the experimental results from training neural networks presented in this thesis have been conducted with one---occasionally two---graphical processing unit (GPU) available. It would be highly beneficial if researchers without such computational limitations extended this analysis to confirm or reject our conclusions, and therefore we made the code available alongside the publications. Another desirable extension of this part of the dissertation would be to compare data augmentation and explicit regularisation in other data modalities beyond natural images, such as speech, text or medical images.

Since one of the motivations for analysing image data augmentation was its connection with visual perception and biological vision, we hypothesised that larger variation in the image transformations seen by a neural network may induce better representational similarity with the inferior temporal cortex. This is the region in the visual cortex where it is possible to decode object classes from measured activations and invariance to transformations has been repeatedly observed. In Chapter~\ref{ch:daugit}, we used representational similarity analysis to compare the features learnt by artificial neural networks and the activations measured in the inferior temporal cortex through fMRI. As hypothesised, we found that models trained with heavier transformations exhibit higher similarity with the visual cortex. This study was the result of a short collaboration in which we tested the idea with a limited experimental setup. Therefore, it would also be desirable to find more evidence of our conclusion in future work, as well as delving into what specific transformations drive invariance in the higher visual cortex.

The last chapter of the block on data augmentation made the connection with visual perception and biological vision more explicit. We departed from the idea that simply applying transformations to the input images and optimising a neural network for classification may not be enough to learn robust features as in the higher visual cortex. We first observed that useful information is lost in the way data augmentation is commonly applied: every time an image is transformed according to a data augmentation scheme, it is fed into the network to compute the classification loss just as any other new image. The transformed image is not just one more image, but a perceptually plausible transformation of another image in the set. With the standard classification objectives this potentially valuable information is simply lost. Could it not be used as an inductive bias?

In order to further exploit the potential inductive bias of data augmentation, in Chapter~\ref{ch:invariance} we proposed \textit{data augmentation invariance}, a simple learning objective inspired by the increasing invariance to identity-preserving transformations observed in the ventral visual stream. Data augmentation invariance combines several novel aspects: First, we perform data augmentation within the training batches, that is we construct the mini-batches by including $M$ transformations of each image. In this way, the model has access to the multiple transformations of an example at once---instead of separated by many iterations---and it potentially reduces the variance of the gradients. Second, we proposed a contrastive loss term that encourages similar representations of images that are transformations of each other. This has been suggested to be a key property of the inferior temporal cortex. Third, we define the data augmentation invariance objective in a layer-wise fashion, that is the representational invariance is optimised at multiple layers of the network. However, we distribute the weights of the loss terms of each layer exponentially along the hierarchy. This aimed to loosely mimic the increasing invariance along the visual cortex. We trained several architectures with data augmentation invariance and the models effectively and efficiently learnt robust representations, without detriment of the classification performance. In contrast, the representations of models trained with the standard categorical cross-entropy loss did not become more invariant to transformations than at the pixel space, in spite of being exposed to data augmentation during training.

Although our results were remarkably consistent across architectures and data sets, future work should find more evidence for the benefits of data augmentation invariance. Furthermore, we are interested in exploring other potential benefits of training with this objective. In particular, we would like to test the representational similarity of the learnt features with the inferior temporal cortex, which inspired this approach. Furthermore, it would be interesting to study whether encouraging invariance to some transformations---rotations, translations, illumination changes---induces invariance to other transformations, such as occlusions as in cutout augmentation.

In the second part of the dissertation, we moved the focus from data augmentation and artificial neural networks to visual attention and salience, using tools of cognitive science and neuroscience, such as eye-tracking and neuroimaging. In Chapter~\ref{ch:globsal}, we proposed and analysed the concept of \textit{global visual salience}. While a large body of scientific literature has studied visual attention and the salience properties of images, it has mostly focused in analysing what parts and features of an image drive eye movements and are more likely to attract fixations. Here, we studied the likelihood of natural images as a whole to attract the initial fixation of a human observer, when presented in competition with other images. For this purpose, we carried out an eye tracking experiment in which we showed participants pairs of images side by side. We trained a simple machine learning algorithm with the behavioural data from the experiment and found that it is possible to predict the direction of the first saccade---left or right---given a pair of images from the data set. This implies that some images have a higher \textit{global visual salience} than others. Specifically, faces and images with social content are most likely to be fixated first. Importantly, we also found that global salience is largely independent from the local salience properties of the images. 

We believe our experimental data can be further used to study aspects of human visual attention of competing stimuli, since we mostly focused on the direction of the first fixation upon stimulus presentation. Therefore, we open sourced the data and the code of our analyses. In particular, it would be interesting to study the reaction times and engagement with the stimuli during the duration of the trials so as to find if there exist differences depending on the nature of the two images, for instance. Another interesting direction would be to more deeply study the visual properties of the images and find out whether it is possible to predict the global visual attention of novel images. Further, we hypothesised that global salience could be used as a tool or metric to better understand the visual attention behaviour of humans with conditions such as the autism spectrum disorder.

Finally, in Chapter~\ref{ch:imageid}, we analysed the relationship between the local salience maps of natural images and the brain activations in the early visual cortex. In particular, we followed up a previous study that demonstrated the possibility to identify natural images from brain activity using the low-parametric population receptive field (pRF) model and contrast information from the images. In our work, we extended that study by analysing the discriminability of salience maps. We compared contrast and salience maps computed with two distinct image salience models, one based on low-level features and the other based on high-level features learnt by a deep neural network. We found that salience, especially based on low-level features, is significantly more predictive of brain activity than contrast. This suggests that the activations in the early visual cortex contain information about various properties of the images, likely driven by feedback connectivity from higher areas. Moreover, the results in this chapter provided additional evidence for the possibility of studying properties of the visual cortex through predictive models based on simple tools such as the pRF model.

Before concluding this dissertation, I would like to briefly discuss some ethical considerations and the societal and environmental impact of the work presented here. First, although compared to much of the deep learning literature the computational resources used for this work were small, some of the results of this thesis required training multiple neural network models, especially for Chapter~\ref{ch:daugreg}. Training these models certainly contributed negatively on the environment with emmision of carbon dioxide. In order to disseminate my work and engage with other scientists, I travelled by plane to attend several conferences, which also had a negative impact on climate change. I strongly advocate minimising the impact of scientific activity on the environment. One way of positively contributing to reduce this impact is through data sharing. Hence, we have made available much of the data collected for this work, which will also hopefully contribute to more open science. Currently, deep neural networks are remarkably energy-inneficient compared to brains. Incorporating better inductive biases, as we have discussed in this thesis, may contribute to more efficient machine learning algorithms. Second, while I do not envision a direct negative use of the work presented here, I believe that as work that aims to advance our technology, it has the potential of being misused or negatively impact our society. As Professor Ruha Benjamin puts it, ``technology can exclude without being explicitly designed for it''. I hope this is not the case of my work and I explicitly disapprove the use of the results, conclusions, data and code related to this work for applications that incite racism, sexism or unequal treatment of marginalised groups.

In sum, in this dissertation we have presented the results of various projects connecting different fields, such as machine learning, cognitive science and computational neuroscience. While science clearly needs the depth of very narrow studies, we have here tried to show the supplementary value of an interdisciplinary approach to science. In particular, I believe that understanding the nature of learning systems---both algorithms and brains---requires the collaboration of scientists of multiple disciplines, as many other researchers have argued before me. Learning algorithms will become more effective and efficient by incorporating insights from the brain; and we will deepen our understanding of the brain by using the tools of improved machine learning. 
}

